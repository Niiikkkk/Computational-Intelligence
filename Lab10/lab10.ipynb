{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: Sunday, December 17 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "* Reviews: Dies Natalis Solis Invicti ([CET](https://en.wikipedia.org/wiki/Sol_Invictus))\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class State:\n",
    "    def __init__(self,p1,p2):\n",
    "        self.board = np.zeros((3,3))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.current_player = 1 #1 is p1, -1 is p2\n",
    "\n",
    "    def available_positions(self):\n",
    "        pos = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board[i,j] == 0:\n",
    "                    pos.append((i,j))\n",
    "        return pos\n",
    "    \n",
    "    def make_move(self, position):\n",
    "        if position not in self.available_positions():\n",
    "            return None\n",
    "        self.board[position]=self.current_player\n",
    "        self.current_player = self.current_player*-1\n",
    "\n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(3 * 3))\n",
    "        return self.boardHash\n",
    "\n",
    "    def check_winner(self):\n",
    "        #check if rows contains 3 or -3 (some one win)\n",
    "        for i in range(3): \n",
    "            if sum(self.board[i,:]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1 #player 1 won\n",
    "        for i in range(3): #loop on the rows\n",
    "            if sum(self.board[i,:]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1 #player 2 won\n",
    "        \n",
    "        #check if col contains 3 or -3\n",
    "        for i in range(3):\n",
    "            if sum(self.board[:,i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "        for i in range(3):\n",
    "            if sum(self.board[:,i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        \n",
    "        #check diagonal win\n",
    "        diag_sum = sum([self.board[i,i] for i in range(3)])\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd= True\n",
    "            return 1\n",
    "        if diag_sum == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "        diag_sum = sum([self.board[i,3-i-1] for i in range(3)])\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd= True\n",
    "            return 1\n",
    "        if diag_sum == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "        #here no one won..\n",
    "        if len(self.available_positions())==0 :\n",
    "            self.isEnd = True\n",
    "            return 0 #no one won\n",
    "        \n",
    "        return None #Here there are still moves, so keep playing !!!\n",
    "    \n",
    "    def reward(self):\n",
    "        result = self.check_winner()\n",
    "\n",
    "        if result == 1:\n",
    "            self.p1.give_rew(1)\n",
    "            self.p2.give_rew(0)\n",
    "        elif result == -1:\n",
    "            self.p1.give_rew(0)\n",
    "            self.p2.give_rew(1)\n",
    "        else:\n",
    "            self.p1.give_rew(0.5)\n",
    "            self.p2.give_rew(0.5)\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "    def showBoard(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, 3):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, 3):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')    \n",
    "\n",
    "    def train(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            while not self.isEnd:\n",
    "                # Player 1\n",
    "                positions = self.available_positions()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.current_player)\n",
    "                # take action and upate board state\n",
    "                self.make_move(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                # check board status if it is end\n",
    "\n",
    "                win = self.check_winner()\n",
    "                if win is not None:\n",
    "                    # self.showBoard()\n",
    "                    # ended with p1 either win or draw\n",
    "                    self.reward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Player 2\n",
    "                    positions = self.available_positions()\n",
    "                    p2_action = self.p2.chooseAction(positions, self.board, self.current_player)\n",
    "                    self.make_move(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "\n",
    "                    win = self.check_winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.reward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "\n",
    "    def test(self):\n",
    "        while not self.isEnd:\n",
    "            # Player 1\n",
    "            positions = self.available_positions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.current_player)\n",
    "            # take action and upate board state\n",
    "            self.make_move(p1_action)\n",
    "            self.showBoard()\n",
    "            # check board status if it is end\n",
    "            win = self.check_winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Player 2\n",
    "                positions = self.available_positions()\n",
    "                p2_action = self.p2.chooseAction(positions, self.board, self.current_player)\n",
    "\n",
    "                self.make_move(p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.check_winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        print(self.p2.name, \"wins!\")\n",
    "                    else:\n",
    "                        print(\"tie!\")\n",
    "                    self.reset()\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [-1., -1.,  1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = State(1,2)\n",
    "move = x.available_positions()\n",
    "x.make_move(move[0])\n",
    "x.make_move(move[6])\n",
    "x.make_move(move[4])\n",
    "x.make_move(move[7])\n",
    "x.make_move(move[8])\n",
    "x.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLPlayer:\n",
    "    def __init__(self, name, exp_rate = 0.3):\n",
    "        self.name = name\n",
    "        self.states = []  # record all positions taken\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {}  # state -> value\n",
    "\n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(3*3))\n",
    "        return boardHash\n",
    "\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "\n",
    "    def chooseAction(self, positions, current_board, symbol):\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board)\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                # print(\"value\", value)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "        # print(\"{} takes action {}\".format(self.name, action))\n",
    "        return action\n",
    "    \n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "\n",
    "    def give_rew(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name \n",
    "    \n",
    "    def chooseAction(self, positions,current_board, symbol):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "    \n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    \n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "            \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = \"random\"\n",
    "\n",
    "    def chooseAction(self, positions,current_board, symbol):\n",
    "        x = np.random.randint(0,len(positions)-1)\n",
    "        return positions[x]\n",
    "    \n",
    "    def addState(self,state):\n",
    "        pass\n",
    "\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "            \n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def give_rew(self,rew):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounds 0\n",
      "Rounds 1000\n",
      "Rounds 2000\n",
      "Rounds 3000\n",
      "Rounds 4000\n",
      "Rounds 5000\n",
      "Rounds 6000\n",
      "Rounds 7000\n",
      "Rounds 8000\n",
      "Rounds 9000\n"
     ]
    }
   ],
   "source": [
    "p1 = RLPlayer(\"computer\")\n",
    "p2 = RandomPlayer(\"random\")\n",
    "\n",
    "st = State(p1,p2)\n",
    "st.train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "computer wins!\n"
     ]
    }
   ],
   "source": [
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "st.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
