{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T12:18:05.944385400Z",
     "start_time": "2023-12-26T12:18:05.837495Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from game import Game, Move, Player\n",
    "from QL_Player import QLPlayer\n",
    "from RL_Player import RLPlayer, train, test\n",
    "from MinMax_Player import MinMaxPlayer\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T12:18:05.952623100Z",
     "start_time": "2023-12-26T12:18:05.945385600Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def choose_action(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "        from_pos = (random.randint(0, 4), random.randint(0, 4))\n",
    "        move = random.choice([Move.TOP, Move.BOTTOM, Move.LEFT, Move.RIGHT])\n",
    "        return from_pos, move\n",
    "    \n",
    "    def give_rew(self, reward):\n",
    "        pass\n",
    "\n",
    "    def add_state(self,s):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T12:22:47.689927Z",
     "start_time": "2023-12-26T12:18:05.964407800Z"
    }
   },
   "outputs": [],
   "source": [
    "g = Game()\n",
    "\n",
    "# Q-Learning\n",
    "alpha = 0.1\n",
    "epsilon = 0.3\n",
    "discount_factor = 0.9\n",
    "epochs = 10000\n",
    "num_test_games = 1000\n",
    "\n",
    "#player1 = QLPlayer(player=0, alpha=alpha, epsilon=epsilon, discount_factor=discount_factor)\n",
    "#player2 = QLPlayer(player=1, alpha=alpha, epsilon=epsilon, discount_factor=discount_factor)\n",
    "#Trainer_player1, Trained_player2 = train(player1, player2, g, epochs=epochs)\n",
    "\n",
    "#player1.save_policy('player1_QL')\n",
    "#player2.save_policy('player2_QL')\n",
    "\n",
    "#player1.load_policy('player1_QL')\n",
    "#random_player = RandomPlayer()\n",
    "#test(player1, random_player, num_test_games)\n",
    "\n",
    "# Reinforcement Learning\n",
    "player1 = RLPlayer(player=0, alpha=alpha, epsilon=epsilon, discount_factor=discount_factor)\n",
    "player2 = RLPlayer(player=1, alpha=alpha, epsilon=epsilon, discount_factor=discount_factor)\n",
    "#Trainer_player1, Trained_player2 = train(player1, player2, g, epochs=epochs)\n",
    "\n",
    "#player1.save_policy('player1_RL')\n",
    "#player2.save_policy('player2_RL')\n",
    "\n",
    "#player1.load_policy('player1_QL')\n",
    "\n",
    "#test(player1, random_player, num_test_games)\n",
    "#train(player1, player2, g, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_player = RandomPlayer()\n",
    "#test(random_player, player2, num_test_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel min max capire come salvare le possibili mosse da fare coi relativi values. Poi fare la choose_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -1 -1  0  1]\n",
      " [-1 -1 -1  0 -1]\n",
      " [-1 -1  0  0  0]\n",
      " [ 1 -1  0  0  1]\n",
      " [ 1  1  0  0  1]]\n",
      "Wins: 0.1\n"
     ]
    }
   ],
   "source": [
    "LVL = [(4,0),(3,23),(2,28),(1,32)]\n",
    "\n",
    "p1 = MinMaxPlayer(0,LVL)\n",
    "g = Game()\n",
    "p2 = RandomPlayer()\n",
    "tests = 1000\n",
    "win_o = 0\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(tests):\n",
    "    win = g.play(p1,p2)   \n",
    "    print(g._board)\n",
    "    if win == 0:\n",
    "        win_o+=1\n",
    "\n",
    "print(f\"Wins: {win_o/tests * 100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
