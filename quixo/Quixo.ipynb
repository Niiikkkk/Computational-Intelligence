{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e744312a",
   "metadata": {},
   "source": [
    "# Quixo\n",
    "---\n",
    "<p align=\"center\">\n",
    "<img style=\"float:center\" src=\"../images/quixo.jpg\" alt=\"drawing\" width=\"300\" height=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc39b12bb2717018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T22:49:09.190852200Z",
     "start_time": "2024-01-14T22:49:08.733717400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint, random, choice\n",
    "from game import Move, Player\n",
    "from CustomGameClass import Quixo as Game\n",
    "from tqdm import trange\n",
    "from typing import Literal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc888e539ec8455",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Reinforcement Learning Player\n",
    "---\n",
    "\n",
    "This class represents a player that uses Reinforcement Learning to make decisions in Quixo.\n",
    "\n",
    "Attributes:\n",
    "- ``epochs`` (int): The number of training epochs.\n",
    "- ``alpha`` (float): The learning rate.\n",
    "- ``discount_factor`` (float): The discount factor of the Bellman equation.\n",
    "- ``min_exploration_rate`` (float): The minimum exploration rate during training.\n",
    "- ``exploration_decay_rate`` (float): The rate at which the exploration rate decays during training.\n",
    "- ``opponent`` (Player): The opponent player.\n",
    "- ``states`` (list): A list to store the states visited during a game.\n",
    "- ``state_value`` (dict): A dictionary to store the value of each state.\n",
    "- ``training_phase`` (bool): A boolean to indicate if the player is training or not. It basically enables the exploration if it is true, otherwise it uses only the `state_value` dictionary to make decisions.\n",
    "\n",
    "Methods:\n",
    "- ``give_rew(reward)``: Placeholder method for giving reward to the player.\n",
    "- ``add_state(state)``: Adds to the ``states`` array the state that a player has seen during a game.\n",
    "- ``reset()``: Reset the ``states`` array to be able to start a new game.\n",
    "- ``make_move(game)``: Chooses an action to take based on the current game state that can be random or based on the value of the dictionary. It takes from the dictionary, for each possible move, the value associated with the state of the board with the move performed. The maximum value will be the move to execute. We use the following recursive (bellman equation) formula to compute the state-value table: \n",
    "$$\n",
    "V(S_t) \\leftarrow V(S_t) + \\alpha * (\\gamma * V(S_t +1) - V(S_t))\n",
    "$$\n",
    "- ``update_state_value_table(reward)``: Updates the values of the ``states_value`` dictionary based on the states that the player has seen during the game and the reward that they have provided.\n",
    "- ``game_reward(player)``: Calculates the reward for the player in the current game.\n",
    "- ``train()``: Trains the player using reinforcement learning.\n",
    "- ``save_policy(name)``: Saves the state value table to a file.\n",
    "- ``load_policy(file)``: Loads the state value table from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41f3f43236fc839f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T22:49:09.202170400Z",
     "start_time": "2024-01-14T22:49:09.198372700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RLPlayer(Player):\n",
    "    def __init__(self, epochs: int,\n",
    "                 alpha: float,\n",
    "                 discount_factor: float,\n",
    "                 min_exploration_rate: float,\n",
    "                 exploration_decay_rate: float,\n",
    "                 opponent: 'Player',\n",
    "                 training_phase: bool) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = 1\n",
    "        self.min_exploration_rate = min_exploration_rate\n",
    "        self.exploration_decay_rate = exploration_decay_rate\n",
    "        self.opponent = opponent\n",
    "        self.training_phase = training_phase\n",
    "        self.states=[]\n",
    "        self.state_value = {}\n",
    "    \n",
    "    def give_rew(self, reward):\n",
    "        pass\n",
    "    \n",
    "    def add_state(self, state):\n",
    "        self.states.append(state)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "    \n",
    "    def make_move(self, game: Game) -> tuple[tuple[int, int], Move]:\n",
    "        available_moves = get_possible_moves(game, game.get_current_player())\n",
    "        if self.training_phase and (random() < self.exploration_rate):  # do exploration\n",
    "            return choice(available_moves)\n",
    "        else:  # do exploitation\n",
    "            value_max = -999\n",
    "            for move in available_moves:\n",
    "                tmp = game.get_board()\n",
    "                game._Quixo__move(move[0], move[1], game.get_current_player())\n",
    "                next_status = convert_matrix_board_to_tuple(game.get_board())\n",
    "                game.set_board(tmp)\n",
    "                value = 0 if self.state_value.get(next_status) is None else self.state_value.get(next_status)\n",
    "                if value > value_max:\n",
    "                    value_max = value\n",
    "                    action = move\n",
    "        return action\n",
    "        \n",
    "    def update_state_value_table(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.state_value.get(st) is None:\n",
    "                self.state_value[st] = 0\n",
    "            current_q_value = self.state_value[st]\n",
    "            reward = current_q_value + self.alpha * (self.discount_factor * reward - current_q_value)\n",
    "            self.state_value[st] = reward\n",
    "        \n",
    "    def game_reward(self, player: 'RLPlayer')-> Literal[-10, 0, 10]:\n",
    "        if self == player:\n",
    "            return 10\n",
    "        else:\n",
    "            return -10\n",
    "    \n",
    "    def train(self, player_name='') -> None:\n",
    "        \n",
    "        all_rewards = []\n",
    "        # define how many episodes to run\n",
    "        pbar = trange(self.epochs)\n",
    "        # define the players\n",
    "        players = (self, self.opponent)\n",
    "        \n",
    "        for epochs in pbar:\n",
    "            game = Game()\n",
    "            rewards = 0\n",
    "            winner = -1\n",
    "            players = (players[1], players[0])\n",
    "            player_idx = 1\n",
    "            \n",
    "            while winner < 0:\n",
    "                # change player\n",
    "                player_idx = (player_idx + 1) % 2\n",
    "                player = players[player_idx]\n",
    "                game.switch_player()\n",
    "                \n",
    "                ok = False\n",
    "                if self == player:\n",
    "                    while not ok:\n",
    "                        from_pos, slide = self.make_move(game)\n",
    "                        ok = game._Quixo__move(from_pos, slide, game.get_current_player())\n",
    "                        state_after_move = convert_matrix_board_to_tuple(game.get_board())\n",
    "                        self.add_state(state_after_move)\n",
    "                        \n",
    "                else:\n",
    "                    while not ok:\n",
    "                        from_pos, slide = player.make_move(game)\n",
    "                        ok = game._Quixo__move(from_pos, slide, game.get_current_player())\n",
    "                winner = game.check_winner()\n",
    "            \n",
    "            # update the exploration rate\n",
    "            self.exploration_rate = np.clip(\n",
    "                np.exp(-self.exploration_decay_rate * epochs), self.min_exploration_rate, 1\n",
    "            )\n",
    "            \n",
    "            reward = self.game_reward(player)\n",
    "            self.update_state_value_table(reward)\n",
    "            rewards += reward\n",
    "            self.reset()\n",
    "            all_rewards.append(rewards)\n",
    "            pbar.set_description(f'rewards value: {rewards}, current exploration rate: {self.exploration_rate:2f}')\n",
    "        \n",
    "        plot_training_trends(all_rewards, filename=f\"{player_name} trained against {self.opponent.__class__.__name__}\")\n",
    "        \n",
    "        print(f'** Last 50_000 episodes - Mean rewards value: {sum(all_rewards[-50_000:]) / 50_000:.2f} **')\n",
    "\n",
    "    def save_policy(self, name):\n",
    "        fw = open(name, 'wb')\n",
    "        pickle.dump(self.state_value, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def load_policy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.state_value = pickle.load(fr)\n",
    "        fr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5563081a6eef8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## MinMax Player\n",
    "---\n",
    "\n",
    "This class represents a player who uses the MinMax algorithm to make decisions in the game. The MinMax algorithm is a search algorithm that is used in two-player games to make optimal decisions.\n",
    "\n",
    "Attributes:\n",
    "- ``playerPlaying`` (int): The player who is currently playing.\n",
    "- ``levels_depth`` (list): A list of tuples, where each tuple contains the depth level and the maximum number of possible moves for that depth level.\n",
    "\n",
    "Methods:\n",
    "- ``game_evaluation``: Evaluate the game state based on the current player and depth. If player X wins, the reward is 1, otherwise it is -1. If player O plays instead, the rewards are reversed.\n",
    "- ``min_max``: Perform the Minimax algorithm to determine the best move for the current player. This method takes as input the current game, the alpha and beta values (used for alpha-beta pruning, a technique for reducing the number of nodes evaluated by the MinMax algorithm), and the current depth of the search tree. If the depth is zero or if there is a winner in the game, the method returns the game rating and no moves. Otherwise, for each possible move, it creates a copy of the game, makes the move, and recursively calls the min_max method on the copy of the game. If the returned rating is greater than alpha, alpha is updated and the move is considered the best move. If beta is less than or equal to alpha, the cycle stops for alpha-beta pruning.\n",
    "The process is similar for the case where the current player is non-zero, with the difference that we try to minimize the rating instead of maximizing it.\n",
    "- ``choose_action``: Choose the best action (move) for the current player using the Minimax algorithm. The method starts by getting all possible moves for the current player using the `get_possible_moves` function. It then calculates the search depth for the MinMax algorithm based on the number of possible moves. This is done through a for loop that passes through the `levels_Depth` list. If the number of possible moves is greater than a certain value, the depth is set to a certain level. The cycle stops as soon as a level is found that does not exceed the number of possible moves. The method then calls the `min_max` method to determine the best move for the current player. Finally, the method returns the best move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "508616c445755cc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T22:49:09.212332300Z",
     "start_time": "2024-01-14T22:49:09.205679800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MinMaxPlayer(Player):\n",
    "    def __init__(self, playerPlaying, levels_depth):\n",
    "        super().__init__()\n",
    "        self.moves_value = []\n",
    "        self.playerPlaying = playerPlaying\n",
    "        self.levels_depth = levels_depth\n",
    "\n",
    "    def game_evaluation(self, game: Game, depth):\n",
    "        win = game.check_winner()\n",
    "        ret = 0 + depth\n",
    "        if win == 0 and self.playerPlaying == 0:\n",
    "            ret = 100 + depth\n",
    "        elif win == 0 and self.playerPlaying == 1:\n",
    "            ret = -100 - depth\n",
    "        elif win == 1 and self.playerPlaying == 1:\n",
    "            ret = 100 + depth\n",
    "        elif win == 1 and self.playerPlaying == 0:\n",
    "            ret = - 100 - depth\n",
    "        return ret\n",
    "\n",
    "    def min_max(self, game: 'Game', alpha, beta, depth):\n",
    "        if depth <= 0 or game.check_winner() != -1:\n",
    "            return self.game_evaluation(game, depth), None\n",
    "        best_move = None\n",
    "        if game.current_player == self.playerPlaying:\n",
    "            for move in get_possible_moves(game, game.get_current_player()):\n",
    "                tmp = game.get_board()\n",
    "                g = Game()\n",
    "                g.set_board(tmp)\n",
    "                g.current_player = self.playerPlaying\n",
    "                g._Quixo__move(move[0], move[1], g.get_current_player())\n",
    "                g.current_player = 1 - self.playerPlaying\n",
    "                eval, _ = self.min_max(g, alpha, beta, depth - 1)\n",
    "                if eval > alpha:\n",
    "                    alpha = eval\n",
    "                    best_move = move\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return alpha, best_move\n",
    "        else:\n",
    "            for move in get_possible_moves(game, game.get_current_player()):\n",
    "                tmp = game.get_board()\n",
    "                g = Game()\n",
    "                g.set_board(tmp)\n",
    "                g.current_player = 1 - self.playerPlaying\n",
    "                g._Quixo__move(move[0], move[1], g.get_current_player())\n",
    "                g.current_player = self.playerPlaying\n",
    "                eval, _ = self.min_max(g, alpha, beta, depth - 1)\n",
    "                if eval < beta:\n",
    "                    beta = eval\n",
    "                    best_move = move\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return beta, best_move\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "        possibleMoves = get_possible_moves(game, game.get_current_player())\n",
    "        possibleMoveCount = len(possibleMoves)\n",
    "\n",
    "        depth = 0\n",
    "        for depthLvl in self.levels_depth:\n",
    "            if possibleMoveCount > depthLvl[1]:\n",
    "                depth = depthLvl[0]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        _, move = self.min_max(game, -math.inf, math.inf, depth)\n",
    "\n",
    "        return move\n",
    "\n",
    "    def give_rew(self, reward):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372aa8b26ec52f69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Utility functions\n",
    "---\n",
    "\n",
    "- ``convert_matrix_to_tuple``: Convert the matrix board representation to a tuple representation.\n",
    "- ``get_possible_moves``: Returns a list of possible moves for the player. It returns a list of tuples, where each tuple contains the move coordinates and the move direction. Each move is a tuple of the form (row, column, direction). The direction is a string that can be either 'up', 'down', 'left' or 'right'.\n",
    "- `test_player`: Test the performance of a player against another player. The method takes as input the two players, the number of games to play, and the name of the two players just to specify them in the plot. The method prints the number of wins for the first player and the number of wins for the second player.\n",
    "- ``plot_total_win_rate``: Creates a bar graph to display the total number of wins of two players in a game. The generated image is saved in the ``images`` folder.\n",
    "- ``plot_training_trends``: Creates a graph to visualize the trend of total rewards while training a reinforcement learning agent. Within the function, the average of the rewards is calculated every 500 training steps. The generated image is saved in the ``images`` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7ee66971b395087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T22:49:09.224977100Z",
     "start_time": "2024-01-14T22:49:09.216848300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_matrix_board_to_tuple(board):\n",
    "    \"\"\"\n",
    "    Converts a matrix board to a tuple representation.\n",
    "\n",
    "    Args:\n",
    "        board (list): The matrix board to be converted.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The converted tuple representation of the board.\n",
    "    \"\"\"\n",
    "    current_board = tuple(tuple(riga) for riga in board)\n",
    "    return current_board\n",
    "\n",
    "def get_possible_moves(game: 'Game', player: int) -> list[tuple[tuple[int, int], Move]]:\n",
    "    \"\"\"\n",
    "    Get a list of possible moves for a given player in the game.\n",
    "\n",
    "    Args:\n",
    "        game (Game): The game object representing the current state of the game.\n",
    "        player (int): The player for whom to find the possible moves.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[tuple[int, int], Move]]: A list of tuples, where each tuple contains the coordinates of a possible move\n",
    "        and the corresponding move direction.\n",
    "\n",
    "    \"\"\"\n",
    "    # possible moves:\n",
    "    # - take border empty and fill the hole by moving in the 3 directions\n",
    "    # - take one of your blocks on the border and fill the hole by moving in the 3 directions\n",
    "    # 44 at start possible moves\n",
    "    pos = set()\n",
    "    for r in [0, 4]:\n",
    "        for c in range(5):\n",
    "            if game.get_board()[r, c] == -1 or game.get_board()[r, c] == player:\n",
    "                if r == 0 and c == 0:  # OK\n",
    "                    pos.add(((c, r), Move.BOTTOM))\n",
    "                    pos.add(((c, r), Move.RIGHT))\n",
    "                elif r == 0 and c == 4:  # OK\n",
    "                    pos.add(((c, r), Move.BOTTOM))\n",
    "                    pos.add(((c, r), Move.LEFT))\n",
    "                elif r == 4 and c == 0:  # OK\n",
    "                    pos.add(((c, r), Move.TOP))\n",
    "                    pos.add(((c, r), Move.RIGHT))\n",
    "                elif r == 4 and c == 4:  # OK\n",
    "                    pos.add(((c, r), Move.TOP))\n",
    "                    pos.add(((c, r), Move.LEFT))\n",
    "                elif r == 0:  # OK\n",
    "                    pos.add(((c, r), Move.BOTTOM))\n",
    "                    pos.add(((c, r), Move.LEFT))\n",
    "                    pos.add(((c, r), Move.RIGHT))\n",
    "                elif r == 4:  # OK\n",
    "                    pos.add(((c, r), Move.TOP))\n",
    "                    pos.add(((c, r), Move.LEFT))\n",
    "                    pos.add(((c, r), Move.RIGHT))\n",
    "    for c in [0, 4]:\n",
    "        for r in range(5):\n",
    "            if game.get_board()[r, c] == -1 or game.get_board()[r, c] == player:\n",
    "                if r == 0 and c == 0:  # OK\n",
    "                    pos.add(((c, r), Move.BOTTOM))\n",
    "                    pos.add(((c, r), Move.RIGHT))\n",
    "                elif r == 0 and c == 4:  # OK\n",
    "                    pos.add(((c, r), Move.BOTTOM))\n",
    "                    pos.add(((c, r), Move.LEFT))\n",
    "                elif r == 4 and c == 0:  # OK\n",
    "                    pos.add(((c, r), Move.TOP))\n",
    "                    pos.add(((c, r), Move.RIGHT))\n",
    "                elif r == 4 and c == 4:  # OK\n",
    "                    pos.add(((c, r), Move.TOP))\n",
    "                    pos.add(((c, r), Move.LEFT))\n",
    "                elif c == 0:\n",
    "                    pos.add(((c, r), Move.TOP))\n",
    "                    pos.add(((c, r), Move.RIGHT))\n",
    "                    pos.add(((c, r), Move.BOTTOM))\n",
    "                elif c == 4:\n",
    "                    pos.add(((c, r), Move.TOP))\n",
    "                    pos.add(((c, r), Move.LEFT))\n",
    "                    pos.add(((c, r), Move.BOTTOM))\n",
    "    return list(pos)\n",
    "\n",
    "def test_player(player1, player2, num_games, name_player1, name_player2):\n",
    "    \"\"\"\n",
    "    Test the performance of two players in a series of games.\n",
    "\n",
    "    Parameters:\n",
    "    player1 (object): The first player object.\n",
    "    player2 (object): The second player object.\n",
    "    num_games (int): The number of games to be played.\n",
    "    name_player1 (str): The name of the first player.\n",
    "    name_player2 (str): The name of the second player.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    g = Game()\n",
    "    player1_wins = 0\n",
    "    player2_wins = 0\n",
    "    draws = 0\n",
    "    games = 0\n",
    "    for _ in range(num_games):\n",
    "        winner = g.play(player1, player2)\n",
    "        games += 1\n",
    "        g.reset()\n",
    "        if winner == 0:\n",
    "            player1_wins += 1\n",
    "        if winner == 1:\n",
    "            player2_wins += 1\n",
    "        if winner == -1:\n",
    "            draws += 1\n",
    "    \n",
    "    plot_total_win_rate(player1_wins, player2_wins, draws, name_player1, name_player2)\n",
    "    print(f\"{name_player1} won {player1_wins / num_games * 100}%\")\n",
    "    print(f\"{name_player2} won {player2_wins / num_games * 100}%\")\n",
    "    print(f\"Draws: {draws / num_games * 100}%\")\n",
    "\n",
    "def plot_total_win_rate(wins_player1, wins_player2, draws, name_player1, name_player2):\n",
    "    \"\"\"\n",
    "    Plots the total win rate of two players.\n",
    "\n",
    "    Parameters:\n",
    "    - wins_player1 (int): Number of wins for player 1.\n",
    "    - wins_player2 (int): Number of wins for player 2.\n",
    "    - draws (int): Number of draws.\n",
    "    - name_player1 (str): Name of player 1.\n",
    "    - name_player2 (str): Name of player 2.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.bar([name_player1, name_player2, 'draws'], [wins_player1, wins_player2, draws], color=['blue', 'orange', 'green'])\n",
    "    plt.ylabel('Number of games')\n",
    "    plt.savefig(f\"images/{name_player1} wins vs {name_player2} wins.png\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_trends(total_rewards: [int], filename=''):\n",
    "    \"\"\"\n",
    "    Plots the training trends of the total rewards.\n",
    "\n",
    "    Args:\n",
    "        total_rewards (list[int]): List of total rewards obtained during training.\n",
    "        filename (str, optional): Name of the file to save the plot. Defaults to ''.\n",
    "    \"\"\"\n",
    "    mean_array = np.mean(np.array(total_rewards).reshape(-1, 500), axis=1)\n",
    "    index = np.arange(0, len(total_rewards), 500)\n",
    "    plt.plot(index, mean_array, label='Mean rewards value')\n",
    "    plt.ylabel('Mean rewards value')\n",
    "    plt.xlabel('Index')\n",
    "    plt.savefig(f\"images/{filename} training_trends.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5077d8d",
   "metadata": {},
   "source": [
    "## Random Player Definition\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8770ff3f8377b1b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T22:49:09.226984900Z",
     "start_time": "2024-01-14T22:49:09.222970100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "        from_pos = (randint(0, 4), randint(0, 4))\n",
    "        move = choice([Move.TOP, Move.BOTTOM, Move.LEFT, Move.RIGHT])\n",
    "        return from_pos, move\n",
    "\n",
    "    def give_rew(self, reward):\n",
    "        pass\n",
    "\n",
    "    def add_state(self, s):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99272dd2",
   "metadata": {},
   "source": [
    "## Human Player Definition\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d8a9c35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T22:49:09.239022200Z",
     "start_time": "2024-01-14T22:49:09.226984900Z"
    }
   },
   "outputs": [],
   "source": [
    "class HumanPlayer(Player):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "            available_moves = get_possible_moves(game, game.get_current_player())\n",
    "            while True:\n",
    "                row = int(input(\"Input your action row:\"))\n",
    "                col = int(input(\"Input your action col:\"))\n",
    "                from_pos = (row, col)\n",
    "                move = int(input(\"Input your action move: (1 for top, 2 for bottom, 3 for left, 4 for right):\"))\n",
    "                if move == 1:\n",
    "                    move = Move.TOP\n",
    "                elif move == 2:\n",
    "                    move = Move.BOTTOM\n",
    "                elif move == 3:\n",
    "                    move = Move.LEFT\n",
    "                elif move == 4:\n",
    "                    move = Move.RIGHT\n",
    "                else:\n",
    "                    print(\"Invalid move, please input again\")\n",
    "                    continue\n",
    "                \n",
    "                if (from_pos, move) in available_moves:\n",
    "                    return from_pos, move\n",
    "                else:\n",
    "                    print(\"Invalid move, please input again\")\n",
    "                    continue\n",
    "\n",
    "    def give_rew(self, reward):\n",
    "        pass\n",
    "\n",
    "    def add_state(self, s):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2415c1",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "---\n",
    "- ``epochs``: training epochs\n",
    "- ``alpha``: learning rate\n",
    "- ``discount_factor``: the discount rate of the Bellman equation\n",
    "- ``min_exploration_rate``: the minimum rate for exploration during the training phase\n",
    "- ``exploration_decay_rate``: the exploration decay rate used during the training\n",
    "- ``training_phase``: a boolean value that indicates if the player is in training phase or not. It basically enables the exploration if it is true, otherwise it uses only the `state_value` dictionary to make decisions.\n",
    "- ``RandomP``: the opponent to play against that use a Random strategy for the RL training\n",
    "- ``MinMaxP``: the opponent to play against that use a MinMax strategy for the RL testing. It takes as input the `level_depth`, a list of tuples, where each tuple contains the depth level and the maximum number of possible moves for that depth level. For example if there are 5 possible moves, the depth level is 4, if there are 40 possible moves, the depth level is 1.\n",
    "- ``num_games``: number of games for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "543dae82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T22:49:09.239022200Z",
     "start_time": "2024-01-14T22:49:09.231716400Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "alpha = 0.1\n",
    "discount_factor = 0.95\n",
    "min_exploration_rate=0.01\n",
    "exploration_decay_rate=5e-6\n",
    "training_phase=True\n",
    "RandomP = RandomPlayer()\n",
    "MinMaxP = MinMaxPlayer(0, [(4,0),(3,23),(2,28),(1,32)])\n",
    "num_games = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362a90d",
   "metadata": {},
   "source": [
    "## Let's do some computation: RL Player trained against Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19a19cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rewards value: -10, current exploration rate: 0.999980: 100%|██████████| 5/5 [00:00<00:00, 309.26it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 5 into shape (500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m rl_agent_RandomOpponent \u001b[38;5;241m=\u001b[39m RLPlayer(\n\u001b[1;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m      4\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     training_phase\u001b[38;5;241m=\u001b[39mtraining_phase\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# train the RL player\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mrl_agent_RandomOpponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRL_Player_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 109\u001b[0m, in \u001b[0;36mRLPlayer.train\u001b[0;34m(self, player_name)\u001b[0m\n\u001b[1;32m    106\u001b[0m     all_rewards\u001b[38;5;241m.\u001b[39mappend(rewards)\n\u001b[1;32m    107\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrewards value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrewards\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, current exploration rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m \u001b[43mplot_training_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_rewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mplayer_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m trained against \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m** Last 50_000 episodes - Mean rewards value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(all_rewards[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50_000\u001b[39m:])\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m50_000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m **\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[51], line 142\u001b[0m, in \u001b[0;36mplot_training_trends\u001b[0;34m(total_rewards, filename)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_training_trends\u001b[39m(total_rewards: [\u001b[38;5;28mint\u001b[39m], filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    Plots the training trends of the total rewards.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m        filename (str, optional): Name of the file to save the plot. Defaults to ''.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     mean_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_rewards\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    143\u001b[0m     index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(total_rewards), \u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m    144\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(index, mean_array, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean rewards value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 5 into shape (500)"
     ]
    }
   ],
   "source": [
    "# create the RL player\n",
    "rl_agent_RandomOpponent = RLPlayer(\n",
    "    epochs=epochs,\n",
    "    alpha=alpha,\n",
    "    discount_factor=discount_factor,\n",
    "    min_exploration_rate=min_exploration_rate,\n",
    "    exploration_decay_rate=exploration_decay_rate,\n",
    "    opponent=RandomP,\n",
    "    training_phase=training_phase\n",
    ")\n",
    "# train the RL player\n",
    "rl_agent_RandomOpponent.train(player_name='RL_Player_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f67c53",
   "metadata": {},
   "source": [
    "## Test Reinforcement Learning Player vs Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc05178fcd495a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T23:03:33.767654100Z",
     "start_time": "2024-01-14T23:02:29.045320500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rl_player = RLPlayer(\n",
    "    epochs=epochs,\n",
    "    alpha=alpha,\n",
    "    discount_factor=discount_factor,\n",
    "    min_exploration_rate=min_exploration_rate,\n",
    "    exploration_decay_rate=exploration_decay_rate,\n",
    "    opponent=RandomP,\n",
    "    training_phase=False\n",
    ")\n",
    "\n",
    "rl_player.load_policy('RL_player_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf683719776545aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T15:49:43.773014300Z",
     "start_time": "2024-01-14T15:49:26.470191100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_player(rl_player, RandomP, num_games, 'RL_player_1(first_move)', 'Random Player')\n",
    "test_player(RandomP, rl_player, num_games, 'Random Player', 'RL_player_1(second_move)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb8158a7e7b1d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### RL Player results\n",
    "\n",
    "- RL Player 1\n",
    "  - ``epochs`` = 500000,\n",
    "  - ``alpha`` = 0.1,\n",
    "  - ``discount_factor`` = 0.95,\n",
    "  - ``min_exploration_rate`` = 0.01,\n",
    "  - ``exploration_decay_rate`` = 1e-5,\n",
    "   \n",
    "  **Results**\n",
    "  - Last 50000 episodes - Mean rewards value: 6.44\n",
    "  - win rate vs ``RandomPlayer`` in 1000 games (RL always first move) - 90%\n",
    "  -  win rate vs ``RandomPlayer`` in 1000 games (Random always first move) - 74%\n",
    "  \n",
    "- RL Player 2\n",
    "  - ``epochs`` = 750000,\n",
    "  - ``alpha`` = 0.1,\n",
    "  - ``discount_factor`` = 0.95,\n",
    "  - ``min_exploration_rate`` = 0.01,\n",
    "  - ``exploration_decay_rate`` = 5e-6,\n",
    "   \n",
    "  **Results**\n",
    "  - Last 50000 episodes - Mean rewards value: 6.16\n",
    "  - win rate vs ``RandomPlayer`` in 1000 games (RL always first move) - 88%\n",
    "  -  win rate vs ``RandomPlayer`` in 1000 games (Random always first move) - 63%\n",
    "\n",
    "RL Player 1 is the best policy we obtained, and we saved it in ``RL_player_1``. We will use it for the next tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a08d3",
   "metadata": {},
   "source": [
    "## Test MinMax Player vs Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ec8ea2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Player(first_move) won 100.0%\n",
      "Random Player won 0.0%\n",
      "Draws: 0.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Player won 0.0%\n",
      "MinMax Player(second_move) won 100.0%\n",
      "Draws: 0.0%\n"
     ]
    }
   ],
   "source": [
    "MinMaxP = MinMaxPlayer(0, [(4,0),(3,23),(2,28),(1,32)])\n",
    "test_player(MinMaxP, RandomP, num_games, 'MinMax Player(first_move)', 'Random Player')\n",
    "MinMaxP = MinMaxPlayer(1, [(4,0),(3,23),(2,28),(1,32)])\n",
    "test_player(RandomP, MinMaxP, num_games, 'Random Player', 'MinMax Player(second_move)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176f11f",
   "metadata": {},
   "source": [
    "## Test MinMax Player vs RL Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO non ha molto senso secondo me metterli a confronto perchè succedono sempre le stesse cose quindi il risultato dipende da come è andata l'exploration nel reinforcement learning \n",
    "\n",
    "test_player(MinMaxP, rl_player, num_games, 'MinMax Player(first_move)', 'RL Player')\n",
    "test_player(rl_player, MinMaxP, num_games, 'RL Player(first_move)', 'MinMax Player')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d91786",
   "metadata": {},
   "source": [
    "## Results and conclusions\n",
    "---\n",
    "\n",
    "We consider a game as a draw if it lasts more than 200 moves (100 moves for player). This is because the game can last forever. In fact, if the two players play optimally, the game will never end.\n",
    "\n",
    "### Reinforcement Learning training trends\n",
    "<div class=\"container\">\n",
    "    <img src=\"images/RL_Player_2 trained against RandomPlayer training_trends.png\">\n",
    "    <img src=\"images/RL_Player_1 trained against RandomPlayer training_trends.png\">\n",
    "</div>\n",
    "\n",
    "### Reinforcement Learning (RL_player_1) vs Random Player\n",
    "<div class=\"container\">\n",
    "    <img src=\"images/RL_player_1(first_move) wins vs Random Player wins.png\">\n",
    "    <img src=\"images/Random Player wins vs RL_player_1(second_move) wins.png\">\n",
    "</div>\n",
    "\n",
    "### Reinforcement Learning (RL_player_2) vs Random Player\n",
    "<div class=\"container\">\n",
    "    <img src=\"images/RL_player_2(first_move) wins vs Random Player wins.png\">\n",
    "    <img src=\"images/Random Player wins vs RL_player_2(second_move) wins.png\">\n",
    "</div>\n",
    "\n",
    "### MinMax Player vs Random Player\n",
    "\n",
    "<div class=\"container\">\n",
    "    <img src=\"images/MinMax Player(first_move) wins vs Random Player wins.png\">\n",
    "    <img src=\"images/Random Player wins vs MinMax Player(second_move) wins.png\">\n",
    "</div>\n",
    "\n",
    "### MinMax Player vs Reinforcement Learning Player (RL_player_1)\n",
    "\n",
    "<div class=\"container\">\n",
    "    <img src=\"images/MinMax Player(first_move) wins vs RL Player wins.png\">\n",
    "    <img src=\"images/RL Player(first_move) wins vs MinMax Player wins.png\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14911d53",
   "metadata": {},
   "source": [
    "## Let's play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO risolvere problema stampa board, non so perché la stampa avviene dopo la richiesta della mossa\n",
    "\n",
    "rl_player = RLPlayer(\n",
    "    epochs=epochs,\n",
    "    alpha=alpha,\n",
    "    discount_factor=discount_factor,\n",
    "    min_exploration_rate=min_exploration_rate,\n",
    "    exploration_decay_rate=exploration_decay_rate,\n",
    "    opponent=RandomP,\n",
    "    training_phase=False\n",
    ")\n",
    "human_player = HumanPlayer()\n",
    "\n",
    "rl_player.load_policy('RL_player')\n",
    "g = Game()\n",
    "winner = g.play(rl_player, human_player, print_flag=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
